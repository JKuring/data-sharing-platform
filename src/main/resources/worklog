2017年3月21日
继承aggregation：
1、完成代码移动
2、SssLauncher 中已添加spark conf配置
3、需要编写java 调用 scala 该类中launch 方法
4、考虑返回消息中的hive路径、或table name

整体：
需要添加项目所需配置，检查配置是否涵盖项目脚本需求

2017年3月22日

1、21号工作取消，因为要使用SparkSubmit模式提交任务
2、已修改spark 配置xml和解析类
3、重新修改SssLauncher为 main类 没有测试 传参对不对
4、注意所有配置文件需要放在hdfs上，因为是submit模式，确认源scala代码中也是读取hdfs 已确认是cluster模式
5、按照新的需求重新编写SssLauncher，检查SlsLauncher代码

2017年3月23日

1、22日的事情已经完成
2、所有需要的参数已经转换为一个String[]发送出去，但是需要在scala端解析参数
3、后期所有业务相关配置需要通过ws通知来修改参数，并持久化在服务中（暂时理解）

2017年3月24日

1、已完成22日事情
2、需要仔细检查汇聚

2017年3月27日

1、测试框架，mq消息收发跑通：剩余aggregate的没有测
2、由于后期需要移植job到数据库，所以load中的job剥离了table的耦合
3、把utils的共用东西都放到了common中

2017年3月28日

1、测试 aggregate的spark 测试完成